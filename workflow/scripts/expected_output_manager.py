# =================================================================================================
#     Input Manager Utility Functions for aDNA Pipeline
# =================================================================================================
# This script provides helper functions for managing input files and sample metadata in the pipeline.
# Functions include file discovery, reference handling, and sample identification.

import os
import logging
# -----------------------------------------------------------------------------------------------
# Skip existing files based on configuration
def skip_existing_files(expected_outputs):

    # Filter out files that already exist if the skip_existing_files option is enabled
    if config.get("pipeline", {}).get("global", {}).get("skip_existing_files", True) == False:
        return expected_outputs
    
    logging.info("Checking for existing files to skip...")

    expected_outputs_existing = []
    expected_outputs_not_existing = []

    # Check for existing files and filter them out
    for output in expected_outputs:
        if os.path.exists(output):
            expected_outputs_existing.append(output)
        else:
            expected_outputs_not_existing.append(output)

    # Log existing files that will be skipped
    if len(expected_outputs_existing) > 0:
        logging.info("The following files already exist and will be skipped:")
        for existing_file in expected_outputs_existing:
            logging.info("\t" + "- Skipping: " + existing_file)
       
    return expected_outputs_not_existing

# -----------------------------------------------------------------------------------------------
# Generate all input file paths required for the 'all' rule in Snakemake
# This function collects all expected output files for each species and sample, ensuring that
# downstream rules have the correct input targets for completion. It is typically used to define
# the 'all' rule in the Snakefile, which triggers the entire workflow.
def get_expected_outputs_from_pipeline(wildcards):
    # Initialize the list to hold all required input file paths
    expected_output = []

    # Loop over each species defined in the config (must be available in the global scope)
    for species in config["species"]:
        # For each species, gather expected output file paths from all relevant processing stages
        expected_output += get_expexted_output_raw_read_processing(species)
        expected_output += get_expected_output_reference_processing(species)
        expected_output += get_expected_output_dynamics_processing(species)
        expected_output += get_expected_output_summary_processing(species)

    # Optionally skip files that already exist to avoid redundant processing
    expected_output = skip_existing_files(expected_output)

    # Log all determined inputs for debugging and traceability
    logging.info("Determined input for rule 'all':")
    for input in expected_output:
        logging.info("\t" + "- Requesting: " + input)

    # Return the complete list of input file paths
    return expected_output
